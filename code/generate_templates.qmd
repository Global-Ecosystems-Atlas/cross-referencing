---
title: "Generate membership matrix templates"
author: "Ben Cresswell"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
 html_document:
    code_folding: show
    collapse: no
    df_print: paged
    fig_caption: yes
    fig_height: 6
    fig_width: 10
    highlight: textmate
    theme: spacelab
    toc: yes
    toc_float: yes
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
# Set options, housekeeping
knitr::opts_chunk$set(
	echo = FALSE,
	include = TRUE,
	message = FALSE,
	warning = FALSE)
```


# Introduction
This file takes information from the main database and generates templates for the IUCN crosswalk tables. It uses the `data_review` sheet from the GEA Google Sheet, which contains metadata about datasets that have been reviewed and passed the GEA criteria.


# Housekeeping
```{r}
# Load required libraries
library(glue) #for string manipulation
library(fs) #for file system operations
library(readxl)  #for reading excel files
library(googlesheets4) #for reading google sheets
library(tidyverse)  #for data wrangling etc
rm(list=ls())
```

# Authenticate with the Google Service Account if available in the environment variables
```{r}
gsa_json <- Sys.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", unset = NA)

if (!is.na(gsa_json) && nchar(gsa_json) > 0) {
  temp_json <- tempfile(fileext = ".json")
  writeLines(gsa_json, temp_json)
  gs4_auth(path = temp_json)
}
```

# Load main database/catalogue and subset source data
Notes:
* This is for datasets that have moved to GEA_pass
* Want to switch the function to purrr-based method
```{r}
source_data <- read_sheet(
  "https://docs.google.com/spreadsheets/d/1P-xus66mTxY-9-a8jZgzwh3KVlL2Yvh6HzJ8rbmT1bY", 
  sheet = "Data_Review_MASTER", 
  trim_ws = TRUE, 
  col_types = "c") |> 
  filter(QAQC_pass == TRUE) |> 
  filter(!is.na(n_map_classes))
```

# Load efg codes
```{r}
efg_codes <- read_csv(
  "https://raw.githubusercontent.com/Global-Ecosystems-Atlas/metadata/refs/heads/main/pixel-values/efg_pixelvalues.csv") |> 
  pull(2) |> 
  unique() |> 
  replace_na("NA") |> 
  as.character()
```
# Make helper functions
```{r}
# safe integer for n_map_classes
safe_int <- function(x, data_id = NA_character_, band = NA_character_) {
  n <- suppressWarnings(as.integer(x))
  if (is.na(n) || n < 1) {
    warning(glue("Invalid n_map_classes '{x}' for {data_id}/{band}; using n = 1"))
    return(1L)
  }
  n
}

# ensure efg_codes is a character vector and unique
efg_codes <- as.character(efg_codes)
if (length(unique(efg_codes)) != length(efg_codes)) {
  stop("efg_codes must be unique names")
}

# desired column order
front_cols <- c(
  "crossref_date", "crossref_by", "GET_vsn",
  "Source_ID", "data_id_code", "band_layer_name",
  "in_class_field_name", "in_class_value",
  "in_class_description", "in_class_description_detail"
)
all_cols <- c(front_cols, efg_codes)
```


# Output directory
```{r}
output_root <- here::here("resources/01-membership-matrix-templates")
dir_create(output_root, recurse = TRUE)
```

# Make templates per dataset
```{r}
# Function
make_dataset_template <- function(df_subset) {
  # df_subset: subset of source_data for a single data_id_code
  data_id <- unique(df_subset$data_id_code)
  if (length(data_id) != 1) stop("df_subset must contain exactly one data_id_code")
  
  # Ensure Source_ID present (take first non-NA if multiple)
  source_id <- df_subset$Source_ID[which(!is.na(df_subset$Source_ID))[1] %||% 1]
  
  # For each band, create a block of n rows
  band_blocks <- df_subset %>%
    mutate(
      .n_rows = map_int(n_map_classes, ~ safe_int(.x, data_id = data_id, band = band_layer_name))
    ) %>%
    # iterate rows to make per-band tibble
    pmap(function(Source_ID, data_id_code, license = NULL, get_alignment_firspass = NULL,
                  stage_1_pass = NULL, analyst_id = NULL, documentation_provided = NULL,
                  documentation_score = NULL, band_layer_name, year_start = NULL, year_end = NULL,
                  n_map_classes = NULL, .n_rows, ...) {
      n <- as.integer(.n_rows)
      
      # fixed columns for this band
      fixed <- tibble(
        crossref_date = "",         # left empty for manual fill
        crossref_by = "",
        Source_ID = as.character(Source_ID %||% source_id),
        data_id_code = as.character(data_id_code),
        band_layer_name = as.character(band_layer_name),
        in_class_field_name = "",
        in_class_value = "",
        in_class_description = "",
        in_class_description_detail = ""
      )
      
      # named EFG blanks (strings "")
      efg_blank <- set_names(rep("", length(efg_codes)), efg_codes) %>% 
        as_tibble()  # single-row tibble with named columns
      
      band_tbl <- bind_cols(fixed, efg_blank)
      band_tbl[rep(1, n), , drop = FALSE]
    }) %>%
    bind_rows()
  
  # enforce column order (add any missing columns if necessary)
  missing_cols <- setdiff(all_cols, names(band_blocks))
  if (length(missing_cols) > 0) {
    band_blocks <- bind_cols(band_blocks, as_tibble(set_names(rep(list(""), length(missing_cols)), missing_cols)))
  }
  band_blocks <- band_blocks %>% select(all_of(all_cols))
  
  # ensure all cells are character and empty strings (no NA)
  band_blocks <- band_blocks %>%
    mutate(across(everything(), ~ replace_na(as.character(.x), "")))
  
  # write to file inside dataset subfolder
  out_dir <- path(output_root, data_id)
  dir_create(out_dir, recurse = TRUE)
  out_file <- path(out_dir, glue("{data_id}_membmat_template.csv"))
  write_csv(band_blocks, out_file, na = "")
  
  message("Wrote template: ", out_file)
  invisible(out_file)
}

# Run 
source_data %>%
  group_by(data_id_code) %>%
  group_split() %>%
  walk(make_dataset_template)

```


```{r}
#END
```

